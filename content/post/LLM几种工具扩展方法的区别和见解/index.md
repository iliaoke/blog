---
title: LLM几种工具扩展方法的区别和见解
description: LLM几种工具扩展方法的区别和见解
date: 2026-02-02
#image: cover.jpg
categories:
    - 技术
tags:
    - LLM
    - Ai
    - 分析
#weight: 1       
---
# LLM几种工具扩展方法的区别和见解
在讨论「LLM + 工具」时，常见误解是认为模型具备直接联网或执行代码的能力。更准确的工程表述为：

- **LLM 本质上是一个“语言决策器”**：它接收上下文与指令，产出下一步该说什么、该做什么。
- **真正的执行发生在模型之外**：例如 HTTP 请求、数据库查询、运行脚本、读写文件、调用内部服务等。
- 所谓“工具扩展”，核心就是：**让 LLM 按约定输出结构化意图（参数/动作），由外部系统执行，再把结果回灌给 LLM 继续推理**。

在这个框架下，当前主流的工具扩展思路大致可以归为三类：`Tool Calls`、`MCP`、`Skills`。它们解决的是同一个问题：如何把“模型的意图”可靠地转化为“系统可执行的动作”，区别主要在 **标准化程度、桥接成本、上下文管理方式、生态适配**。

## 1. Tool Calls：模型内置的结构化调用能力

`Tool Calls` 通常是部分大模型原生支持的一种能力：在提示中提供工具的描述（名称、参数 schema、用途）后，模型可在适当时刻返回“工具调用结构体”（或类似 JSON 的结果），由应用侧解析并执行。

### 工作机制（典型流程）

1. 应用向 LLM 提供：工具清单（名字/描述/参数）+ 当前对话上下文。
2. LLM 输出：要调用哪个工具，以及对应参数。
3. 应用执行工具：调用接口、执行脚本、查询数据库等。
4. 应用把执行结果再发回 LLM：让它基于新上下文继续回答。

### 优点

- **实现门槛低**：在单体应用中即可完成“模型 + 工具”的集成与落地。
- **自由度高**：可定义多种工具形态（函数、HTTP、脚本、工作流节点）。
- **响应链路短**：不强制引入额外协议与客户端/服务端组件。

### 缺点

- **桥接代码成本高**：
  - 需要在应用侧判断模型是否触发调用，并处理多次调用、失败重试、超时、权限控制等。
  - 工具越多、流程越复杂，应用侧的“编排逻辑”会迅速膨胀。
- **缺乏统一标准**：不同模型、不同 SDK 的调用结构体字段可能不一致，兼容性与迁移成本更高。
- **容易出现“半结构化”问题**：当模型输出不完全符合 schema 时，通常需要额外的容错解析与纠偏。

### 适用场景

- **小规模工具集**、流程不复杂的应用。
- 适用于需要 **完全掌控编排逻辑**（例如对稳定性、安全、审计有要求），且能够投入相应工程成本的场景。

## 2. MCP：更严格的协议化工具生态

`MCP（Model Context Protocol）` 可视为一套“工具接入协议/标准”，目标是以统一方式暴露工具能力：

- 有 **MCP Server**：负责提供工具（Tools）、资源（Resources）等能力。
- 有 **MCP Client**：由宿主环境（IDE/Agent 框架/应用）连接 Server，负责调用与回传。

相较于 Tool Calls 的“自行约定结构体并自行编排”，MCP 更强调 **一致性**：工具的描述、调用、传参与返回形式均尽量规范化。

### 优点

- **标准化与可复用性更强**：工具一旦按协议暴露，多个宿主/客户端理论上可复用。
- **生态协作更容易**：团队内/社区可以共享 MCP Server，形成工具市场式的组合。
- **边界更清晰**：工具与宿主分离，便于权限、隔离、审计与部署治理。

### 缺点

- **上下文与交互轮次更容易膨胀**：
  - 协议层 + 工具返回内容 + 多轮调用，会显著抬高 token 成本。
  - 若缺少“摘要/裁剪/缓存/结构化回传”等策略，容易出现 **上下文膨胀**，进而影响模型对关键信息的聚焦。
- **调试链路更长**：出现问题时需要定位是模型决策、宿主编排、协议实现还是工具实现。

### 适用场景

- 工具需要 **跨项目/跨团队复用**，或者希望形成稳定生态。
- 工具有明显的 **权限边界与隔离要求**（例如内部数据、生产系统操作）。
- 适用于以更高工程复杂度换取“长期可维护性与标准化收益”的场景。

## 3. Skills：更“产品化”的工具/能力封装（共识驱动）

在工程实现层面，`Skills` 与 `Tool Calls` 的关键差异主要体现在“工具接入与编排方式”上：

- **工具实现**：两者均允许自行编写工具代码，因而在功能自由度与可扩展性上差异不大。
- **连接与调用**：`Tool Calls` 通常需要以代码形式实现调用链路与编排逻辑，包括触发判定、参数提取与校验、失败重试、超时控制、结果回传等；`Skills` 则倾向于允许以自然语言描述触发条件与执行规则，将部分连接、调用与判断下沉至宿主环境与 AI 侧处理。

因此，`Skills` 在一定程度上实现了“保留工具自由度”与“降低调用与编排成本”之间的平衡。

`Skills` 可视为由 Claude/IDE 等产品提出的一类能力形态，更强调将“工具调用 + 编排 + 交互规范”整体产品化。

其未必采用与 MCP 同等严格的协议形式，更偏向一种 **共识驱动的能力抽象**：

- 通过更高层的描述定义“能力/行为”（不局限于函数参数）。
- 宿主环境（比如 IDE、Agent 运行时）负责把这段描述落地成可执行的动作与编排。
- 除了工具执行，还能顺带约束：**语气、注意事项、触发条件、输出格式、偏好策略** 等（这些过去往往只能靠 prompt 或应用逻辑拼接）。

### 优点

- **显著降低桥接成本**：可减少为每个工具编写“触发判断、参数对齐、结果回传”等集成逻辑的工作量，并由宿主侧承担统一编排。
- **更贴近真实工作流**：很多能力并不是单次函数调用能解决的，Skills 更容易表达“步骤/习惯/规则/约束”。
- **对使用方更友好**：对最终用户而言，更接近以“能力包/技能包”的方式启用能力，而非直接集成协议或 SDK。

### 缺点

- **依赖宿主适配**：Skills 的落地效果高度依赖平台（VS Code、Windsurf、Claude 客户端等）如何实现。
- **可迁移性不如强标准**：同一个 Skill，在不同宿主上的行为可能存在差异。
- **边界容易被误解**：其表面上减少显式编码工作，但本质是将编排逻辑由应用侧下沉至宿主侧；
  - 工具本体仍然需要实现；
  - 权限、隔离、审计等工程问题依然存在，只是由平台提供默认实现。

### 适用场景

- 适用于以较低接入成本获得“可用的工具化体验”，尤其是在 IDE/个人生产力场景。
- 工具更多是“增强协作与效率”，而不是“必须强治理的生产系统操作”。

## 总结与趋势判断

这三者在本质上都在做同一件事：**把 LLM 的“意图”变成系统能执行的“动作”，并把结果回灌给 LLM**。区别在于：

- **Tool Calls**：自由、直接，但集成层与兼容性问题需要应用侧自行承担。
- **MCP**：标准化强、生态化潜力大，但工程链路更长；若缺少上下文治理，性能与成本压力会随规模上升而显著增加。
- **Skills**：更产品化、更高层抽象，把桥接与编排下沉到宿主环境，显著降低接入成本。

综上所述，**长期更具潜力的是 Skills 路线**。其价值在于将“工具调用”从纯工程集成问题提升为“使用体验与默认工作流”的问题：

- **Tool Calls 的主要成本在桥接层与模型差异**。
- **MCP 的主要成本在部署/治理/上下文管理的复杂度**。
- **Skills 在体验层面能够缓解前两者的主要问题**：
  - 把桥接交给宿主统一实现；
  - 用更高层的抽象减少无意义的上下文噪声。

随着 Skills 形态被更广泛采用，其隐含约定可能逐步固化为事实标准；较可能的演进路径是：**底层以协议（类似 MCP）保障互通，上层以 Skills 形态保障体验**。